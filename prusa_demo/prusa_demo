import argparse
import cv2
import numpy as np
import time
import sys

#-------------------------------------------------------------------------------
# A single shift-compensation script:
def search_shifts(duo, warp_range = 3):
    (heightCropped, widthCropped) = duo[0].shape

    duo[0,:warp_range] = 0
    duo[0,:,:warp_range] = 0
    duo[0,-warp_range:] = 0
    duo[0,:,-warp_range:] = 0

    # Eliminating possible false positives due to small camera movements:
    warped_array = np.zeros(((warp_range*2+1)**2,heightCropped,widthCropped), dtype = np.float64)
    warped_array_idx = 0
    for idx_x,i in enumerate(range(-warp_range,warp_range+1)):
      for idx_y,j in enumerate(range(-warp_range,warp_range+1)):
          M = np.float32([[1,0,i],[0,1,j]])
          warped = cv2.warpAffine(duo[1],M,(widthCropped,heightCropped))

          warped[:warp_range] = 0
          warped[:,:warp_range] = 0
          warped[-warp_range:] = 0
          warped[:,-warp_range:] = 0

          warped_array[warped_array_idx] = np.abs(warped.astype(np.float64) - duo[0].astype(np.float64))
          warped_array_idx += 1

    warpedMinImg = np.amin(warped_array, axis = 0)
    warpedMin = np.mean(warpedMinImg)

    return warpedMin/(heightCropped*widthCropped),warpedMinImg

#-------------------------------------------------------------------------------
# Seach for minimum with the entire shifted frame
def search_shifts_1(duo, warp_range = 3):
    (heightCropped, widthCropped) = duo[0].shape

    duo[0,:warp_range] = 0
    duo[0,:,:warp_range] = 0
    duo[0,-warp_range:] = 0
    duo[0,:,-warp_range:] = 0

    # Eliminating possible false positives due to small camera movements:
    warped_array = np.zeros(((warp_range*2+1)**2,heightCropped,widthCropped), dtype = np.float64)
    warped_array_idx = 0
    for idx_x,i in enumerate(range(-warp_range,warp_range+1)):
      for idx_y,j in enumerate(range(-warp_range,warp_range+1)):
          M = np.float32([[1,0,i],[0,1,j]])
          warped = cv2.warpAffine(duo[1],M,(widthCropped,heightCropped))

          warped[:warp_range] = 0
          warped[:,:warp_range] = 0
          warped[-warp_range:] = 0
          warped[:,-warp_range:] = 0

          warped_array[warped_array_idx] = np.abs(warped.astype(np.float64) - duo[0].astype(np.float64))
          warped_array_idx += 1

    diff_means = [np.mean(x) for x in warped_array]
    min_mean_index = diff_means.index(min(diff_means))
    warpedMin = min(diff_means)

    return warpedMin/(heightCropped*widthCropped),warped_array[min_mean_index]


# Define a function to convert an RGB frame to grayscale
def to_grayscale(frame):
    # Convert the frame to grayscale
    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    return gray_frame


if __name__ == '__main__':

    parser = argparse.ArgumentParser()
    parser.add_argument(
        '-c', '--compare', dest='compare', default=False, action="store_true",
        help='Show comparison'
    )
    parser.add_argument(
        '-f', '--file', dest='file_path', required=True,
        help='Path to timelapse file'
    )
    parser.add_argument(
        '-w', '--width', dest='width', default=640,
        help='Width'
    )
    parser.add_argument(
        '-H', '--height', dest='height', default=360,
        help='Height'
    )
    args = parser.parse_args()

    # Create a VideoCapture object to read the video
    cap = cv2.VideoCapture(args.file_path)

    prev_frame = None
    output_frames = []

    print("Loading video", end="")
    sys.stdout.flush()
    # Loop through each frame in the video
    while cap.isOpened():
        # Read the frame from the video
        ret, frame = cap.read()
        # If we reached the end of the video, break the loop
        if not ret:
            break

        frame = cv2.resize(frame, (args.width, args.height), interpolation= cv2.INTER_LINEAR)
        # Convert the current frame to grayscale
        gray_frame = to_grayscale(frame)

        frame_blur_kernel_size = 3
        gray_frame = cv2.GaussianBlur(gray_frame,(frame_blur_kernel_size,frame_blur_kernel_size),0)

        # Subtract the current frame from the previous frame
        if prev_frame is not None:
            diff_frame = np.abs(gray_frame.astype(np.float64) - prev_frame.astype(np.float64))
            diff_frame = cv2.cvtColor((4*diff_frame).astype(np.uint8), cv2.COLOR_GRAY2BGR)

            if args.compare:
                _, diff_frame_with_sifts = search_shifts(np.stack([prev_frame, gray_frame]))
                diff_frame_with_sifts = cv2.cvtColor((4*diff_frame_with_sifts).astype(np.uint8), cv2.COLOR_GRAY2BGR)
                _, diff_frame_with_sifts_1 = search_shifts_1(np.stack([prev_frame, gray_frame]))
                diff_frame_with_sifts_1 = cv2.cvtColor((4*diff_frame_with_sifts_1).astype(np.uint8), cv2.COLOR_GRAY2BGR)
        else:
            diff_frame = np.zeros_like(frame)
            if args.compare:
                diff_frame_with_sifts = np.zeros_like(frame)
                diff_frame_with_sifts_1 = np.zeros_like(frame)
        prev_frame = gray_frame

        # Concatenate the original frame and the difference frame horizontally
        output_frame_1 = np.concatenate((frame, diff_frame), axis=1)
        if args.compare:
             output_frame_2 = np.concatenate((diff_frame_with_sifts_1, diff_frame_with_sifts), axis=1)
             output_frame = np.vstack((output_frame_1, output_frame_2))
        else:
             output_frame = output_frame_1

        output_frames.append(output_frame)

        print(".", end="")
        sys.stdout.flush()

    print("done", end="")
    print("\r", end="")  # move cursor to the beginning of the line

    cv2.namedWindow('Video', cv2.WINDOW_NORMAL)

    # Initialize the current frame index
    frame_idx = 0
    while True:
        output_frame = output_frames[frame_idx]
        cv2.putText(output_frame, f'{frame_idx}', (36, 72), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 4, cv2.LINE_AA)

        # Display the processed frame
        cv2.imshow('Video', output_frame)

        key = cv2.waitKey()
        # Check if the user pressed the 'q' key to exit
        if key & 0xFF == ord('q'):
            break
        # Check if the user pressed the right arrow key to advance 1 frame
        elif key == 3: # right arrow key
            frame_idx += 1
        # Check if the user pressed the left arrow key to rewind 1 frame
        elif key == 2: # left arrow key
            frame_idx -= 1

    # Release the VideoCapture object and close the window
    cap.release()
    cv2.destroyAllWindows()
